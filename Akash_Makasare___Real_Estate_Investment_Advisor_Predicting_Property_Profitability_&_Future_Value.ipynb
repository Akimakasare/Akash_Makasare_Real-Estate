{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akimakasare/Akash_Makasare_Real-Estate/blob/main/Akash_Makasare___Real_Estate_Investment_Advisor_Predicting_Property_Profitability_%26_Future_Value.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA Analysis**"
      ],
      "metadata": {
        "id": "rSCA91vNsEGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Data Loading and Cleaning ---\n",
        "file_path = \"India_housing_prices (Akash Makasare).csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with any missing values and ensure numerical columns are of the correct type\n",
        "df_cleaned = df.dropna(subset=['City', 'Price_in_Lakhs', 'Size_in_SqFt', 'Nearby_Schools', 'Nearby_Hospitals', 'Public_Transport_Accessibility', 'Security']).copy()\n",
        "df_cleaned['Size_in_SqFt'] = df_cleaned['Size_in_SqFt'].astype(float)\n",
        "df_cleaned['Price_in_Lakhs'] = df_cleaned['Price_in_Lakhs'].astype(float)\n",
        "\n",
        "\n",
        "# --- 1. Price trends by city ---\n",
        "print(\"\\n--- 1. Price trends by city ---\")\n",
        "# Calculate the median price per city\n",
        "city_price_trends = df_cleaned.groupby('City')['Price_in_Lakhs'].median().sort_values(ascending=False).head(10)\n",
        "print(\"Top 10 Cities by Median Price (in Lakhs):\")\n",
        "print(city_price_trends)\n",
        "\n",
        "# Plotting the top 10 cities\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=city_price_trends.index, y=city_price_trends.values, palette=\"viridis\")\n",
        "plt.title('Top 10 Cities by Median House Price (in Lakhs)')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Median Price (in Lakhs)')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('price_trends_by_city.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: price_trends_by_city.png\")\n",
        "\n",
        "\n",
        "# --- 2. Correlation between area and investment return (Proxy: Price_in_Lakhs) ---\n",
        "print(\"\\n--- 2. Correlation between area (Size_in_SqFt) and investment return (Proxy: Price_in_Lakhs) ---\")\n",
        "# Calculate the correlation coefficient\n",
        "correlation = df_cleaned['Size_in_SqFt'].corr(df_cleaned['Price_in_Lakhs'])\n",
        "print(f\"Pearson Correlation (Size_in_SqFt vs Price_in_Lakhs): {correlation:.4f}\")\n",
        "\n",
        "# Plotting the relationship (sampling for faster plotting if the dataset is too large)\n",
        "df_sample = df_cleaned.sample(n=min(len(df_cleaned), 10000), random_state=42)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Size_in_SqFt', y='Price_in_Lakhs', data=df_sample, alpha=0.6, s=15)\n",
        "plt.title('Area (SqFt) vs. Price (in Lakhs)')\n",
        "plt.xlabel('Size in SqFt')\n",
        "plt.ylabel('Price in Lakhs')\n",
        "plt.grid(True)\n",
        "plt.savefig('area_vs_price_correlation.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: area_vs_price_correlation.png\")\n",
        "\n",
        "\n",
        "# --- 3. Impact of crime rate (Proxy: inverse of Security) on good investment classification (Proxy: Public_Transport_Accessibility) ---\n",
        "print(\"\\n--- 3. Impact of Security (inverse of Crime Rate) on Public Transport Accessibility (Good Investment Classification) ---\")\n",
        "\n",
        "# Create a contingency table (crosstab)\n",
        "crosstab_df = pd.crosstab(df_cleaned['Public_Transport_Accessibility'], df_cleaned['Security'], normalize='index') * 100\n",
        "print(\"Proportion of Security Status by Transport Accessibility (%):\")\n",
        "print(crosstab_df)\n",
        "\n",
        "# Plotting the relationship\n",
        "crosstab_df.plot(kind='bar', stacked=True, figsize=(8, 6))\n",
        "plt.title('Security Status by Public Transport Accessibility')\n",
        "plt.xlabel('Public Transport Accessibility (Good Investment Classification Proxy)')\n",
        "plt.ylabel('Proportion (%)')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Security Status (Inverse of Crime Rate Proxy)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('security_vs_transport_accessibility.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: security_vs_transport_accessibility.png\")\n",
        "\n",
        "\n",
        "# --- 4. Relationship between infrastructure score (Proxy: Nearby_Schools + Nearby_Hospitals) and resale value (Proxy: Price_in_Lakhs) ---\n",
        "print(\"\\n--- 4. Relationship between Infrastructure Score (Schools + Hospitals) and Resale Value (Proxy: Price_in_Lakhs) ---\")\n",
        "# Calculate the Infrastructure Score\n",
        "df_cleaned['Infrastructure_Score'] = df_cleaned['Nearby_Schools'] + df_cleaned['Nearby_Hospitals']\n",
        "\n",
        "# Calculate the correlation coefficient\n",
        "correlation_infra = df_cleaned['Infrastructure_Score'].corr(df_cleaned['Price_in_Lakhs'])\n",
        "print(f\"Pearson Correlation (Infrastructure_Score vs Price_in_Lakhs): {correlation_infra:.4f}\")\n",
        "\n",
        "# Plotting the relationship\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Infrastructure_Score', y='Price_in_Lakhs', data=df_sample.assign(Infrastructure_Score=df_sample['Nearby_Schools'] + df_sample['Nearby_Hospitals']), alpha=0.6, s=15)\n",
        "plt.title('Infrastructure Score (Schools+Hospitals) vs. Price (in Lakhs)')\n",
        "plt.xlabel('Infrastructure Score')\n",
        "plt.ylabel('Price in Lakhs')\n",
        "plt.grid(True)\n",
        "plt.savefig('infrastructure_vs_price_correlation.png')\n",
        "plt.close()\n",
        "print(\"Saved plot: infrastructure_vs_price_correlation.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eqm5jwltqK-",
        "outputId": "b3bbb4de-8a16-46f7-e6aa-a080bf824f0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 1. Price trends by city ---\n",
            "Top 10 Cities by Median Price (in Lakhs):\n",
            "City\n",
            "Mysore        272.945\n",
            "Bhopal        271.295\n",
            "Jaipur        268.260\n",
            "Dehradun      264.380\n",
            "Chennai       263.170\n",
            "Silchar       262.305\n",
            "Cuttack       261.515\n",
            "Mangalore     260.685\n",
            "Nagpur        260.510\n",
            "Vijayawada    260.170\n",
            "Name: Price_in_Lakhs, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-76147593.py:25: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=city_price_trends.index, y=city_price_trends.values, palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot: price_trends_by_city.png\n",
            "\n",
            "--- 2. Correlation between area (Size_in_SqFt) and investment return (Proxy: Price_in_Lakhs) ---\n",
            "Pearson Correlation (Size_in_SqFt vs Price_in_Lakhs): -0.0059\n",
            "Saved plot: area_vs_price_correlation.png\n",
            "\n",
            "--- 3. Impact of Security (inverse of Crime Rate) on Public Transport Accessibility (Good Investment Classification) ---\n",
            "Proportion of Security Status by Transport Accessibility (%):\n",
            "Security                               No        Yes\n",
            "Public_Transport_Accessibility                      \n",
            "High                            50.018219  49.981781\n",
            "Low                             50.031078  49.968922\n",
            "Medium                          49.926817  50.073183\n",
            "Saved plot: security_vs_transport_accessibility.png\n",
            "\n",
            "--- 4. Relationship between Infrastructure Score (Schools + Hospitals) and Resale Value (Proxy: Price_in_Lakhs) ---\n",
            "Pearson Correlation (Infrastructure_Score vs Price_in_Lakhs): -0.0076\n",
            "Saved plot: infrastructure_vs_price_correlation.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL Development **"
      ],
      "metadata": {
        "id": "TLVi-dr1ts7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn numpy\n",
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DSlRtbpduJQI",
        "outputId": "08d5ecb4-930b-4fac-ce59-b4601ea877c5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "# import xgboost as xgb  # Uncomment this if you plan to use XGBoost\n",
        "\n",
        "# Suppress minor warnings for cleaner notebook output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Step 1: Data Loading and Feature Engineering ---\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"India_housing_prices (Akash Makasare).csv\"\n",
        "df = pd.read_csv(file_path, on_bad_lines='skip', engine='python') # Added engine='python'\n",
        "\n",
        "# 1. Clean Data: Drop rows with missing values in key columns\n",
        "key_cols = ['BHK', 'Size_in_SqFt', 'Price_in_Lakhs', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals', 'Public_Transport_Accessibility', 'Property_Type', 'Furnished_Status', 'Security']\n",
        "df_cleaned = df.dropna(subset=key_cols).copy()\n",
        "\n",
        "# 2. Feature Engineering for Targets (Proxies)\n",
        "# Classification Target: Good_Investment (Proxy: High Public Transport Accessibility)\n",
        "df_cleaned['Good_Investment'] = df_cleaned['Public_Transport_Accessibility'].apply(\n",
        "    lambda x: 1 if x == 'High' else 0\n",
        ")\n",
        "\n",
        "# Regression Target: Future_Price_5Y (Proxy: Current Price_in_Lakhs)\n",
        "df_cleaned['Future_Price_5Y'] = df_cleaned['Price_in_Lakhs']\n",
        "\n",
        "\n",
        "# 3. Define Features and Preprocessing Steps\n",
        "numerical_features = ['BHK', 'Size_in_SqFt', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals']\n",
        "categorical_features = ['City', 'Property_Type', 'Furnished_Status', 'Security', 'Owner_Type']\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "    ],\n",
        "    remainder='drop' # Drop all other columns not specified\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# --- Step 2: Classification Model Development (Target: Good_Investment) ---\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"CLASSIFICATION MODEL: Predicting Good_Investment (Proxy: High Transport Access)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define X and y for Classification\n",
        "X_clf = df_cleaned.drop(['Good_Investment', 'Price_in_Lakhs', 'Future_Price_5Y'], axis=1)\n",
        "y_clf = df_cleaned['Good_Investment']\n",
        "\n",
        "# Split Data\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
        "    X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
        ")\n",
        "\n",
        "# --- Model Selection: RandomForestClassifier ---\n",
        "clf_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Train Model\n",
        "clf_model.fit(X_train_clf, y_train_clf)\n",
        "\n",
        "# Predict\n",
        "y_pred_clf = clf_model.predict(X_test_clf)\n",
        "y_proba_clf = clf_model.predict_proba(X_test_clf)[:, 1]\n",
        "\n",
        "# Evaluate Classification Metrics\n",
        "print(\"\\n--- Evaluation Metrics (RandomForestClassifier) ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_clf, y_pred_clf):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test_clf, y_pred_clf):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test_clf, y_pred_clf):.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test_clf, y_proba_clf):.4f}\")\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# --- Step 3: Regression Model Development (Target: Future_Price_5Y) ---\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"REGRESSION MODEL: Predicting Future_Price_5Y (Proxy: Current Price)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Define X and y for Regression\n",
        "X_reg = df_cleaned.drop(['Good_Investment', 'Price_in_Lakhs', 'Future_Price_5Y'], axis=1)\n",
        "y_reg = df_cleaned['Future_Price_5Y']\n",
        "\n",
        "# Split Data\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- Model Selection: Linear Regression (Example) ---\n",
        "# To use other models, uncomment and replace LinearRegression():\n",
        "# regressor_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "# regressor_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "reg_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Train Model\n",
        "reg_model.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Predict\n",
        "y_pred_reg = reg_model.predict(X_test_reg)\n",
        "\n",
        "# Evaluate Regression Metrics\n",
        "# Ensure predictions are non-negative\n",
        "y_pred_reg[y_pred_reg < 0] = 0\n",
        "\n",
        "print(\"\\n--- Evaluation Metrics (Linear Regression) ---\")\n",
        "print(f\"RMSE (Root Mean Squared Error): {np.sqrt(mean_squared_error(y_test_reg, y_pred_reg)):.4f}\")\n",
        "print(f\"MAE (Mean Absolute Error): {mean_absolute_error(y_test_reg, y_pred_reg):.4f}\")\n",
        "print(f\"R-squared ($R^2$): {r2_score(y_test_reg, y_pred_reg):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BR_c7kduFwB",
        "outputId": "966a9f0c-3f84-40d1-8a7b-94d0dca6b522"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "CLASSIFICATION MODEL: Predicting Good_Investment (Proxy: High Transport Access)\n",
            "==================================================\n",
            "\n",
            "--- Evaluation Metrics (RandomForestClassifier) ---\n",
            "Accuracy: 0.6539\n",
            "Precision: 0.3379\n",
            "Recall: 0.0352\n",
            "ROC AUC: 0.5023\n",
            "\n",
            "==================================================\n",
            "REGRESSION MODEL: Predicting Future_Price_5Y (Proxy: Current Price)\n",
            "==================================================\n",
            "\n",
            "--- Evaluation Metrics (Linear Regression) ---\n",
            "RMSE (Root Mean Squared Error): 141.1969\n",
            "MAE (Mean Absolute Error): 122.3189\n",
            "R-squared ($R^2$): -0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLflow Integration**"
      ],
      "metadata": {
        "id": "WIvdPjBKwSdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ui67drqTu1EY",
        "outputId": "d478a585-6244-4cf9-e176-e0aaf5da2c30"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting mlflow-skinny==3.6.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.6.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow)\n",
            "  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.5.4-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, pyngrok, gunicorn, graphql-core, graphql-relay, docker, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed Flask-CORS-6.0.1 databricks-sdk-0.73.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 1. Data Preparation (Reusing previous steps) ---\n",
        "\n",
        "file_path = \"India_housing_prices (Akash Makasare).csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "key_cols = ['BHK', 'Size_in_SqFt', 'Price_in_Lakhs', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals', 'Public_Transport_Accessibility', 'Property_Type', 'Furnished_Status', 'Security']\n",
        "df_cleaned = df.dropna(subset=key_cols).copy()\n",
        "\n",
        "# Feature Engineering for Targets (Proxies)\n",
        "df_cleaned['Good_Investment'] = df_cleaned['Public_Transport_Accessibility'].apply(\n",
        "    lambda x: 1 if x == 'High' else 0\n",
        ")\n",
        "df_cleaned['Future_Price_5Y'] = df_cleaned['Price_in_Lakhs']\n",
        "\n",
        "# Define Features and Preprocessing Steps\n",
        "numerical_features = ['BHK', 'Size_in_SqFt', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals']\n",
        "categorical_features = ['City', 'Property_Type', 'Furnished_Status', 'Security', 'Owner_Type']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "# Define common X and split data\n",
        "X = df_cleaned.drop(['Good_Investment', 'Price_in_Lakhs', 'Future_Price_5Y'], axis=1)\n",
        "y_clf = df_cleaned['Good_Investment']\n",
        "y_reg = df_cleaned['Future_Price_5Y']\n",
        "\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y_clf, test_size=0.2, random_state=42, stratify=y_clf)\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# --- 2. MLflow Setup ---\n",
        "\n",
        "# Set up MLflow tracking (defaults to local `./mlruns` directory)\n",
        "experiment_name = \"Housing_Price_Prediction_EDA\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "print(f\"MLflow Experiment Set: {experiment_name}\")\n",
        "\n",
        "\n",
        "# --- 3. Classification Experiment Function ---\n",
        "\n",
        "def run_classification_experiment(model_class, model_params, model_name, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Trains, evaluates, and logs a classification model using MLflow.\"\"\"\n",
        "    with mlflow.start_run(run_name=model_name) as run:\n",
        "        print(f\"\\nStarting MLflow Run for: {model_name}\")\n",
        "\n",
        "        # 1. Log Parameters\n",
        "        mlflow.log_params(model_params)\n",
        "\n",
        "        # 2. Define Model Pipeline\n",
        "        clf_model = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', model_class(**model_params, random_state=42))\n",
        "        ])\n",
        "\n",
        "        # 3. Train Model\n",
        "        clf_model.fit(X_train, y_train)\n",
        "\n",
        "        # 4. Predict and Evaluate\n",
        "        y_pred = clf_model.predict(X_test)\n",
        "        y_proba = clf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        metrics = {\n",
        "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"precision\": precision_score(y_test, y_pred),\n",
        "            \"recall\": recall_score(y_test, y_pred),\n",
        "            \"roc_auc\": roc_auc_score(y_test, y_proba)\n",
        "        }\n",
        "\n",
        "        # 5. Log Metrics\n",
        "        mlflow.log_metrics(metrics)\n",
        "        print(f\"Metrics Logged: ROC AUC={metrics['roc_auc']:.4f}\")\n",
        "\n",
        "        # 6. Log Model Artifact\n",
        "        # The artifact path will be 'classification_model' within the run\n",
        "        mlflow.sklearn.log_model(\n",
        "            sk_model=clf_model,\n",
        "            artifact_path=\"classification_model\",\n",
        "            registered_model_name=f\"Classification_{model_name}\"\n",
        "        )\n",
        "        print(\"Model artifact logged and registered.\")\n",
        "\n",
        "        return metrics['roc_auc']\n",
        "\n",
        "# --- 4. Regression Experiment Function ---\n",
        "\n",
        "def run_regression_experiment(model_class, model_params, model_name, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Trains, evaluates, and logs a regression model using MLflow.\"\"\"\n",
        "    with mlflow.start_run(run_name=model_name) as run:\n",
        "        print(f\"\\nStarting MLflow Run for: {model_name}\")\n",
        "\n",
        "        # 1. Log Parameters\n",
        "        mlflow.log_params(model_params)\n",
        "\n",
        "        # 2. Define Model Pipeline\n",
        "        reg_model = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('regressor', model_class(**model_params, random_state=42) if 'random_state' in model_class.__init__.__code__.co_varnames else model_class(**model_params))\n",
        "        ])\n",
        "\n",
        "        # 3. Train Model\n",
        "        reg_model.fit(X_train, y_train)\n",
        "\n",
        "        # 4. Predict and Evaluate\n",
        "        y_pred = reg_model.predict(X_test)\n",
        "        y_pred[y_pred < 0] = 0 # Ensure predictions are non-negative\n",
        "\n",
        "        metrics = {\n",
        "            \"rmse\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
        "            \"mae\": mean_absolute_error(y_test, y_pred),\n",
        "            \"r2\": r2_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "        # 5. Log Metrics\n",
        "        mlflow.log_metrics(metrics)\n",
        "        print(f\"Metrics Logged: R2={metrics['r2']:.4f}\")\n",
        "\n",
        "        # 6. Log Model Artifact\n",
        "        # The artifact path will be 'regression_model' within the run\n",
        "        mlflow.sklearn.log_model(\n",
        "            sk_model=reg_model,\n",
        "            artifact_path=\"regression_model\",\n",
        "            registered_model_name=f\"Regression_{model_name}\"\n",
        "        )\n",
        "        print(\"Model artifact logged and registered.\")\n",
        "\n",
        "        return metrics['r2']\n",
        "\n",
        "\n",
        "# --- 5. Running the Experiments ---\n",
        "\n",
        "# Classification Experiments\n",
        "clf_runs = {}\n",
        "clf_runs['LogisticRegression'] = run_classification_experiment(\n",
        "    LogisticRegression, {'solver': 'liblinear', 'C': 1.0}, 'Logistic_Regression_V1',\n",
        "    X_train_clf, X_test_clf, y_train_clf, y_test_clf\n",
        ")\n",
        "clf_runs['RandomForestClassifier'] = run_classification_experiment(\n",
        "    RandomForestClassifier, {'n_estimators': 100, 'max_depth': 10, 'n_jobs': -1}, 'Random_Forest_V1',\n",
        "    X_train_clf, X_test_clf, y_train_clf, y_test_clf\n",
        ")\n",
        "\n",
        "# Regression Experiments\n",
        "reg_runs = {}\n",
        "reg_runs['LinearRegression'] = run_regression_experiment(\n",
        "    LinearRegression, {}, 'Linear_Regression_V1',\n",
        "    X_train_reg, X_test_reg, y_train_reg, y_test_reg\n",
        ")\n",
        "reg_runs['RandomForestRegressor'] = run_regression_experiment(\n",
        "    RandomForestRegressor, {'n_estimators': 100, 'max_depth': 10, 'n_jobs': -1}, 'Random_Forest_V1',\n",
        "    X_train_reg, X_test_reg, y_train_reg, y_test_reg\n",
        ")\n",
        "\n",
        "# --- 6. Final Summary ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MLflow Experiments Completed.\")\n",
        "print(f\"Classification Best ROC AUC: {max(clf_runs.values()):.4f} ({max(clf_runs, key=clf_runs.get)})\")\n",
        "print(f\"Regression Best R2: {max(reg_runs.values()):.4f} ({max(reg_runs, key=reg_runs.get)})\")\n",
        "print(\"View the MLflow UI by running the next code block.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MYevSzwhvBGj",
        "outputId": "bc8d5bae-eb66-4269-a4bb-1b66cf782ef7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/03 01:03:25 INFO mlflow.tracking.fluent: Experiment with name 'Housing_Price_Prediction_EDA' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Experiment Set: Housing_Price_Prediction_EDA\n",
            "\n",
            "Starting MLflow Run for: Logistic_Regression_V1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/03 01:03:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Logged: ROC AUC=0.4993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/12/03 01:03:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Classification_Logistic_Regression_V1'.\n",
            "Created version '1' of model 'Classification_Logistic_Regression_V1'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model artifact logged and registered.\n",
            "\n",
            "Starting MLflow Run for: Random_Forest_V1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/03 01:04:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Logged: ROC AUC=0.4986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/12/03 01:04:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Classification_Random_Forest_V1'.\n",
            "Created version '1' of model 'Classification_Random_Forest_V1'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model artifact logged and registered.\n",
            "\n",
            "Starting MLflow Run for: Linear_Regression_V1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/03 01:04:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Logged: R2=-0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/12/03 01:04:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'Regression_Linear_Regression_V1'.\n",
            "Created version '1' of model 'Regression_Linear_Regression_V1'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model artifact logged and registered.\n",
            "\n",
            "Starting MLflow Run for: Random_Forest_V1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/03 01:06:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics Logged: R2=-0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m2025/12/03 01:07:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model artifact logged and registered.\n",
            "\n",
            "==================================================\n",
            "MLflow Experiments Completed.\n",
            "Classification Best ROC AUC: 0.4993 (LogisticRegression)\n",
            "Regression Best R2: -0.0001 (LinearRegression)\n",
            "View the MLflow UI by running the next code block.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Successfully registered model 'Regression_Random_Forest_V1'.\n",
            "Created version '1' of model 'Regression_Random_Forest_V1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Streamlit App**"
      ],
      "metadata": {
        "id": "wTYPUk69wagS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pandas numpy scikit-learn mlflow plotly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ck4SF05Vwb18",
        "outputId": "57f61a6e-6479-41a1-c443-b9c5b618a891"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.12/dist-packages (3.6.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: mlflow-skinny==3.6.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.6.0)\n",
            "Requirement already satisfied: mlflow-tracing==3.6.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.6.0)\n",
            "Requirement already satisfied: Flask-CORS<7 in /usr/local/lib/python3.12/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: huey<3,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.5.4)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.73.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f443bfd1",
        "outputId": "a49e71e3-3dae-4077-aad7-299b9dc49b3d"
      },
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow.sklearn\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from mlflow.models.signature import infer_signature\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner UI\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- MLFLOW CONFIGURATION AND MODEL LOADING ---\n",
        "# NOTE: This assumes the models were registered locally in Step 4.\n",
        "# We target the Random Forest models which allow for Feature Importance.\n",
        "CLASSIFICATION_MODEL_NAME = \"Classification_Random_Forest_V1\"\n",
        "REGRESSION_MODEL_NAME = \"Regression_Random_Forest_V1\"\n",
        "MODEL_VERSION = \"1\" # Assuming the first version registered\n",
        "\n",
        "# Set up the MLflow tracking URI (defaults to local './mlruns')\n",
        "mlflow.set_tracking_uri(\"file://\" + mlflow.get_tracking_uri().replace(\"file://\", \"\"))\n",
        "\n",
        "\n",
        "@st.cache_resource(show_spinner=\"Loading Models and Data...\")\n",
        "def load_models_and_data():\n",
        "    \"\"\"Loads data, defines preprocessing, and loads trained models from MLflow.\"\"\"\n",
        "    try:\n",
        "        # Load the pipeline components and models\n",
        "        clf_model = mlflow.sklearn.load_model(f\"models:/{CLASSIFICATION_MODEL_NAME}/{MODEL_VERSION}\")\n",
        "        reg_model = mlflow.sklearn.load_model(f\"models:/{REGRESSION_MODEL_NAME}/{MODEL_VERSION}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading models from MLflow Registry. Ensure Step 4 was run and models were registered locally. Error: {e}\")\n",
        "        # Return dummy models to prevent app crash\n",
        "        clf_model = None\n",
        "        reg_model = None\n",
        "\n",
        "    # --- Data Preparation ---\n",
        "    file_path = \"India_housing_prices (Akash Makasare).csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        st.error(f\"File not found: {file_path}. Please ensure the CSV is in the same directory.\")\n",
        "        return None, None, None, None\n",
        "\n",
        "    key_cols = ['BHK', 'Size_in_SqFt', 'Price_in_Lakhs', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals', 'Public_Transport_Accessibility', 'Property_Type', 'Furnished_Status', 'Security', 'Owner_Type', 'City']\n",
        "    df_cleaned = df.dropna(subset=key_cols).copy()\n",
        "\n",
        "    # Feature Engineering for Targets (Proxies)\n",
        "    df_cleaned['Good_Investment'] = df_cleaned['Public_Transport_Accessibility'].apply(\n",
        "        lambda x: 1 if x == 'High' else 0\n",
        "    )\n",
        "    df_cleaned['Future_Price_5Y'] = df_cleaned['Price_in_Lakhs']\n",
        "\n",
        "    # Define features and preprocessor (must be identical to training)\n",
        "    numerical_features = ['BHK', 'Size_in_SqFt', 'Age_of_Property', 'Nearby_Schools', 'Nearby_Hospitals']\n",
        "    categorical_features = ['City', 'Property_Type', 'Furnished_Status', 'Security', 'Owner_Type']\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numerical_features),\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
        "        ],\n",
        "        remainder='drop'\n",
        "    )\n",
        "\n",
        "    # Fit preprocessor on the original features for consistent transformations\n",
        "    X = df_cleaned.drop(['Good_Investment', 'Price_in_Lakhs', 'Future_Price_5Y'], axis=1)\n",
        "    preprocessor.fit(X)\n",
        "\n",
        "    return df_cleaned, clf_model, reg_model, preprocessor\n",
        "\n",
        "# --- Load Data and Models ---\n",
        "df, clf_model, reg_model, preprocessor = load_models_and_data()\n",
        "\n",
        "if df is None:\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# --- FEATURE IMPORTANCE EXTRACTION ---\n",
        "def get_feature_importance(model_pipeline):\n",
        "    \"\"\"Extracts feature importance from the Random Forest model.\"\"\"\n",
        "    try:\n",
        "        # The Random Forest Estimator is the last step in the pipeline\n",
        "        rf_model = model_pipeline.named_steps['classifier'] if 'classifier' in model_pipeline.named_steps else model_pipeline.named_steps['regressor']\n",
        "        importances = rf_model.feature_importances_\n",
        "\n",
        "        # Get feature names from the ColumnTransformer\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "        # Create DataFrame and sort\n",
        "        feature_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "        feature_df['feature'] = feature_df['feature'].str.replace(r'^(num|cat)__', '', regex=True)\n",
        "        return feature_df.sort_values(by='importance', ascending=False)\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Could not extract feature importance. Ensure model is Random Forest. Error: {e}\")\n",
        "        return pd.DataFrame({'feature': ['N/A'], 'importance': [0]})\n",
        "\n",
        "clf_importance_df = get_feature_importance(clf_model)\n",
        "reg_importance_df = get_feature_importance(reg_model)\n",
        "\n",
        "\n",
        "# --- STREAMLIT APP LAYOUT ---\n",
        "st.set_page_config(layout=\"wide\", page_title=\"India Housing Investment Predictor\")\n",
        "\n",
        "st.title(\"🏡 Housing Investment & Price Predictor\")\n",
        "st.markdown(\"Use this application to analyze investment potential and predict the future price of residential properties in India using ML models trained with MLflow.\")\n",
        "\n",
        "\n",
        "# --- SIDEBAR FOR PREDICTION INPUT ---\n",
        "with st.sidebar:\n",
        "    st.header(\"🔮 Property Prediction Form\")\n",
        "\n",
        "    # Input fields for prediction\n",
        "    input_data = {}\n",
        "\n",
        "    # Numerical Inputs\n",
        "    input_data['BHK'] = st.slider(\"BHK (Bedrooms)\", 1, 6, 2)\n",
        "    input_data['Size_in_SqFt'] = st.number_input(\"Size in SqFt\", 500, 10000, 1500)\n",
        "    input_data['Age_of_Property'] = st.slider(\"Age of Property (Years)\", 0, 50, 5)\n",
        "    input_data['Nearby_Schools'] = st.slider(\"Nearby Schools (Count)\", 0, 20, 5)\n",
        "    input_data['Nearby_Hospitals'] = st.slider(\"Nearby Hospitals (Count)\", 0, 20, 2)\n",
        "\n",
        "    # Categorical Inputs\n",
        "    input_data['City'] = st.selectbox(\"City\", df['City'].unique())\n",
        "    input_data['Property_Type'] = st.selectbox(\"Property Type\", df['Property_Type'].unique())\n",
        "    input_data['Furnished_Status'] = st.selectbox(\"Furnished Status\", df['Furnished_Status'].unique())\n",
        "    input_data['Security'] = st.selectbox(\"Security (Yes/No)\", df['Security'].unique())\n",
        "    input_data['Owner_Type'] = st.selectbox(\"Owner Type\", df['Owner_Type'].unique())\n",
        "\n",
        "    # Placeholders for non-used columns to match training schema\n",
        "    # The preprocessor handles these by dropping them, but we need them in the input DataFrame\n",
        "    input_data['Public_Transport_Accessibility'] = 'Low' # Does not affect prediction outcome as it's the target proxy\n",
        "    input_data['Price_in_Lakhs'] = 100 # Dummy value\n",
        "\n",
        "    predict_button = st.button(\"Generate Prediction\")\n",
        "\n",
        "# --- MAIN CONTENT ---\n",
        "\n",
        "# TABS for EDA/Model Insights and Prediction Results\n",
        "tab_predict, tab_insights = st.tabs([\"Prediction Results\", \"Data & Model Insights\"])\n",
        "\n",
        "with tab_predict:\n",
        "    if predict_button:\n",
        "        # Create input DataFrame for prediction\n",
        "        input_df = pd.DataFrame([input_data])\n",
        "\n",
        "        # --- CLASSIFICATION PREDICTION ---\n",
        "        clf_proba = clf_model.predict_proba(input_df)[0]\n",
        "        clf_pred = clf_model.predict(input_df)[0]\n",
        "\n",
        "        is_good_investment = \"YES\" if clf_pred == 1 else \"NO\"\n",
        "        confidence_score = clf_proba[clf_pred] * 100\n",
        "\n",
        "        # --- REGRESSION PREDICTION ---\n",
        "        reg_pred = reg_model.predict(input_df)[0]\n",
        "        estimated_price = max(0, reg_pred) # Price cannot be negative\n",
        "\n",
        "        st.header(\"Prediction Outcomes\")\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.metric(\n",
        "                label=\"Is this a Good Investment?\",\n",
        "                value=is_good_investment,\n",
        "                delta=f\"Confidence: {confidence_score:.2f}%\"\n",
        "            )\n",
        "            st.caption(f\"*Definition of 'Good Investment' used in training: High Public Transport Accessibility.*\")\n",
        "\n",
        "        with col2:\n",
        "            st.metric(\n",
        "                label=\"Estimated Price after 5 Years (Lakhs)\",\n",
        "                value=f\"₹ {estimated_price:,.2f} L\",\n",
        "            )\n",
        "            st.caption(f\"*Note: The 'Future Price' model is a proxy for the current price.*\")\n",
        "\n",
        "    else:\n",
        "        st.info(\"👈 Enter property details in the sidebar and click 'Generate Prediction' to see the results.\")\n",
        "\n",
        "with tab_insights:\n",
        "    st.header(\"📊 Exploratory Data Analysis & Visual Insights\")\n",
        "\n",
        "    # 1. Price Distribution by Property Type\n",
        "    st.subheader(\"Price Distribution by Property Type\")\n",
        "    fig_price_type = px.box(\n",
        "        df,\n",
        "        x='Property_Type',\n",
        "        y='Price_in_Lakhs',\n",
        "        color='Property_Type',\n",
        "        title=\"Price Distribution Across Property Types (Lakhs)\",\n",
        "        log_y=True,\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "    st.plotly_chart(fig_price_type, use_container_width=True)\n",
        "\n",
        "    # 2. Location-wise Price Heatmap (Using City)\n",
        "    st.subheader(\"Average Price by City\")\n",
        "    avg_price_city = df.groupby('City')['Price_in_Lakhs'].mean().sort_values(ascending=False).reset_index()\n",
        "    fig_city_price = px.bar(\n",
        "        avg_price_city,\n",
        "        x='City',\n",
        "        y='Price_in_Lakhs',\n",
        "        color='Price_in_Lakhs',\n",
        "        title=\"Average Property Price per City (Lakhs)\",\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "    st.plotly_chart(fig_city_price, use_container_width=True)\n",
        "\n",
        "    st.header(\"⚙️ Model Insights: Feature Importance\")\n",
        "    col3, col4 = st.columns(2)\n",
        "\n",
        "    if not clf_importance_df.empty and clf_importance_df['importance'].sum() > 0:\n",
        "        with col3:\n",
        "            st.subheader(\"Classification Model Feature Importance\")\n",
        "            fig_clf = px.bar(\n",
        "                clf_importance_df.head(10),\n",
        "                x='importance',\n",
        "                y='feature',\n",
        "                orientation='h',\n",
        "                title=f\"Top 10 Features for {CLASSIFICATION_MODEL_NAME}\",\n",
        "                template=\"plotly_dark\"\n",
        "            )\n",
        "            fig_clf.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "            st.plotly_chart(fig_clf, use_container_width=True)\n",
        "\n",
        "        with col4:\n",
        "            st.subheader(\"Regression Model Feature Importance\")\n",
        "            fig_reg = px.bar(\n",
        "            reg_importance_df.head(10),\n",
        "            x='importance',\n",
        "            y='feature',\n",
        "            orientation='h',\n",
        "            title=f\"Top 10 Features for {REGRESSION_MODEL_NAME}\",\n",
        "            template=\"plotly_dark\"\n",
        "        )\n",
        "        fig_reg.update_layout(yaxis={'categoryorder':'total ascending'})\n",
        "        st.plotly_chart(fig_reg, use_container_width=True)\n",
        "    else:\n",
        "        st.warning(\"Feature importance could not be calculated. Ensure the models loaded are Random Forest based.\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.caption(f\"Models Loaded: Classification ({CLASSIFICATION_MODEL_NAME} V{MODEL_VERSION}), Regression ({REGRESSION_MODEL_NAME} V{MODEL_VERSION})\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This command saves the current Python code to a file named 'streamlit_app.py'\n",
        "# and then executes it using Streamlit and ngrok.\n",
        "\n",
        "# 1. Start ngrok tunnel and get the URL\n",
        "# 2. Run streamlit application using the tunnel URL\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Stop any existing ngrok tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Define the Streamlit command\n",
        "# Assuming 'streamlit_app.py' is the file name for the Canvas content\n",
        "command = [\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\", \"--browser.serverAddress\", \"localhost\"]\n",
        "\n",
        "# Start the Streamlit process in the background\n",
        "process = subprocess.Popen(command)\n",
        "\n",
        "# Open a tunnel to the Streamlit port (8501 is the default Streamlit port)\n",
        "try:\n",
        "    # pyngrok will automatically use the NGROK_AUTHTOKEN environment variable\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit App is running at: {public_url}\")\n",
        "    print(\"Click the link above to view your app.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error opening ngrok tunnel: {e}\")\n",
        "    print(\"You might need to install ngrok or ensure it's on your path.\")\n",
        "\n",
        "# Note: To stop the app, you would typically run:\n",
        "# process.terminate()\n",
        "# ngrok.kill()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XQzi2XCk0fyW",
        "outputId": "4d0ddf91-d508-4967-b5fe-419ed33658de"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-12-03T01:36:39+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: <YOUR_AUTH_TOKEN>\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-12-03T01:36:39+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: <YOUR_AUTH_TOKEN>\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-12-03T01:36:39+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: <YOUR_AUTH_TOKEN>\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error opening ngrok tunnel: The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok authtoken.\\nYour authtoken: <YOUR_AUTH_TOKEN>\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n.\n",
            "You might need to install ngrok or ensure it's on your path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r9UYn3LzwRw",
        "outputId": "1d5768c3-6297-4cbb-bc06-e1939cf2d611"
      },
      "source": [
        "!ngrok config add-authtoken <36BTeHepw8u7wXO3aVPKmSCfIXg_oEFoRGy2JV1T9gm1eFQ5>"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `ngrok config add-authtoken <36BTeHepw8u7wXO3aVPKmSCfIXg_oEFoRGy2JV1T9gm1eFQ5>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6318660",
        "outputId": "fc2dc9f6-27d2-446e-f1be-19f98a700d7e"
      },
      "source": [
        "import os\n",
        "\n",
        "# Replace <YOUR_AUTH_TOKEN> with your actual ngrok authtoken\n",
        "# This sets the NGROK_AUTHTOKEN environment variable for pyngrok to use.\n",
        "os.environ[\"NGROK_AUTHTOKEN\"] = \"36BTeHepw8u7wXO3aVPKmSCfIXg_oEFoRGy2JV1T9gm1eFQ5\"\n",
        "print(\"NGROK_AUTHTOKEN environment variable set.\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NGROK_AUTHTOKEN environment variable set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94b32379",
        "outputId": "1c06b542-3e87-4115-8530-5875eb9d6ea8"
      },
      "source": [
        "# This command saves the current Python code to a file named 'streamlit_app.py'\n",
        "# and then executes it using Streamlit and ngrok.\n",
        "\n",
        "# 1. Start ngrok tunnel and get the URL\n",
        "# 2. Run streamlit application using the tunnel URL\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Stop any existing ngrok tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Define the Streamlit command\n",
        "# Assuming 'streamlit_app.py' is the file name for the Canvas content\n",
        "command = [\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", \"8501\", \"--browser.serverAddress\", \"localhost\"]\n",
        "\n",
        "# Start the Streamlit process in the background\n",
        "process = subprocess.Popen(command)\n",
        "\n",
        "# Open a tunnel to the Streamlit port (8501 is the default Streamlit port)\n",
        "try:\n",
        "    # pyngrok will automatically use the NGROK_AUTHTOKEN environment variable\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit App is running at: {public_url}\")\n",
        "    print(\"Click the link above to view your app.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error opening ngrok tunnel: {e}\")\n",
        "    print(\"You might need to install ngrok or ensure it's on your path.\")\n",
        "\n",
        "# Note: To stop the app, you would typically run:\n",
        "# process.terminate()\n",
        "# ngrok.kill()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit App is running at: NgrokTunnel: \"https://uninterpretively-noneuphonious-tess.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "Click the link above to view your app.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAp0cbYULByTfdGwApi/Y0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}